{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeechPrediction",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnBNcbsT4KZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b5ca2d-38b0-4d1f-b4bd-c8d81f9c7a09"
      },
      "source": [
        "!pip install stop_words\n",
        "from __future__ import print_function\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM, Activation, Dense, Permute, Dropout, add, dot, concatenate, Bidirectional, GRU\n",
        "import tarfile\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from functools import reduce\n",
        "import re\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import pandas as pd\n",
        "from stop_words import get_stop_words\n",
        "from unicodedata import category\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "!unzip '/content/715041_1245709_bundle_archive.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp37-none-any.whl size=32913 sha256=444e332e536ffc475a6df704b0080825865602acde07be28ab9ca54c9102a9da\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Archive:  /content/715041_1245709_bundle_archive.zip\n",
            "  inflating: dialogs.txt             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGf0u90GY2I9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "86d4c107-12ef-402c-c280-176570a70128"
      },
      "source": [
        "df = pd.read_table('/content/dialogs.txt')\n",
        "\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hi, how are you doing?</th>\n",
              "      <th>i'm fine. how about yourself?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "      <td>i've been great. what about you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i've been great. what about you?</td>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "      <td>what school do you go to?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3719</th>\n",
              "      <td>that's a good question. maybe it's not old age.</td>\n",
              "      <td>are you right-handed?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3720</th>\n",
              "      <td>are you right-handed?</td>\n",
              "      <td>yes. all my life.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3721</th>\n",
              "      <td>yes. all my life.</td>\n",
              "      <td>you're wearing out your right hand. stop using...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3722</th>\n",
              "      <td>you're wearing out your right hand. stop using...</td>\n",
              "      <td>but i do all my writing with my right hand.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3723</th>\n",
              "      <td>but i do all my writing with my right hand.</td>\n",
              "      <td>start typing instead. that way your left hand ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3724 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 hi, how are you doing?                      i'm fine. how about yourself?\n",
              "0                         i'm fine. how about yourself?                i'm pretty good. thanks for asking.\n",
              "1                   i'm pretty good. thanks for asking.                  no problem. so how have you been?\n",
              "2                     no problem. so how have you been?                   i've been great. what about you?\n",
              "3                      i've been great. what about you?           i've been good. i'm in school right now.\n",
              "4              i've been good. i'm in school right now.                          what school do you go to?\n",
              "...                                                 ...                                                ...\n",
              "3719    that's a good question. maybe it's not old age.                              are you right-handed?\n",
              "3720                              are you right-handed?                                  yes. all my life.\n",
              "3721                                  yes. all my life.  you're wearing out your right hand. stop using...\n",
              "3722  you're wearing out your right hand. stop using...        but i do all my writing with my right hand.\n",
              "3723        but i do all my writing with my right hand.  start typing instead. that way your left hand ...\n",
              "\n",
              "[3724 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cUEGF1npsTl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8aa6773a-b4ac-4a9d-befd-554f980dcbd1"
      },
      "source": [
        "questions = df['hi, how are you doing?']\n",
        "answers = df[\"i'm fine. how about yourself?\"]\n",
        "\n",
        "def clean_text(text):\n",
        "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", text)\n",
        "#     text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "clean_sentences = []\n",
        "for item in questions:\n",
        "  clean_sentence = clean_text(item)\n",
        "  clean_sentences.append(clean_sentence)\n",
        "\n",
        "clean_sentences[0]\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hi, how are you doing?</th>\n",
              "      <th>i'm fine. how about yourself?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "      <td>i've been great. what about you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i've been great. what about you?</td>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "      <td>what school do you go to?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3719</th>\n",
              "      <td>that's a good question. maybe it's not old age.</td>\n",
              "      <td>are you right-handed?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3720</th>\n",
              "      <td>are you right-handed?</td>\n",
              "      <td>yes. all my life.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3721</th>\n",
              "      <td>yes. all my life.</td>\n",
              "      <td>you're wearing out your right hand. stop using...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3722</th>\n",
              "      <td>you're wearing out your right hand. stop using...</td>\n",
              "      <td>but i do all my writing with my right hand.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3723</th>\n",
              "      <td>but i do all my writing with my right hand.</td>\n",
              "      <td>start typing instead. that way your left hand ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3724 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 hi, how are you doing?                      i'm fine. how about yourself?\n",
              "0                         i'm fine. how about yourself?                i'm pretty good. thanks for asking.\n",
              "1                   i'm pretty good. thanks for asking.                  no problem. so how have you been?\n",
              "2                     no problem. so how have you been?                   i've been great. what about you?\n",
              "3                      i've been great. what about you?           i've been good. i'm in school right now.\n",
              "4              i've been good. i'm in school right now.                          what school do you go to?\n",
              "...                                                 ...                                                ...\n",
              "3719    that's a good question. maybe it's not old age.                              are you right-handed?\n",
              "3720                              are you right-handed?                                  yes. all my life.\n",
              "3721                                  yes. all my life.  you're wearing out your right hand. stop using...\n",
              "3722  you're wearing out your right hand. stop using...        but i do all my writing with my right hand.\n",
              "3723        but i do all my writing with my right hand.  start typing instead. that way your left hand ...\n",
              "\n",
              "[3724 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czW9M7Cup40i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c82adb-9e07-45e5-e19c-7e7e09bc6d26"
      },
      "source": [
        "train_sentences = clean_sentences[:7000]\n",
        "validation_sentences = clean_sentences[7000:]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "tokenizer.fit_on_texts(validation_sentences)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(\n",
        "    train_sentences\n",
        ")\n",
        "validation_sequences = tokenizer.texts_to_sequences(\n",
        "    validation_sentences\n",
        ")\n",
        "\n",
        "train_padded = pad_sequences(train_sequences, maxlen=120, padding='pre', truncating='pre')\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=120, padding='pre', truncating='pre')\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "print(vocab_size)\n",
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "\n",
        "y_train = []\n",
        "y_validate = []\n",
        "for item in range(3724):\n",
        "  y_train.append(item)\n",
        "for item in range(199):\n",
        "  y_validate.append(item)\n",
        "\n",
        "print(len(y_train))\n",
        "print(len(y_validate))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2359\n",
            "3724\n",
            "199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1kZjVSNuD-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2484cc4b-4570-4bc7-abfc-70e44102637a"
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size+1, 50),\n",
        "    GRU(256, return_sequences=True),\n",
        "    GRU(512, return_sequences=False),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_padded, np.array(y_train), batch_size=32, epochs=100)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 50)          118000    \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 256)         236544    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 512)               1182720   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               51300     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2359)              238259    \n",
            "=================================================================\n",
            "Total params: 1,826,823\n",
            "Trainable params: 1,826,823\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "117/117 [==============================] - 25s 25ms/step - loss: nan - accuracy: 6.1770e-04\n",
            "Epoch 2/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.3384e-04\n",
            "Epoch 3/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.8554e-05\n",
            "Epoch 4/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 2.0962e-05\n",
            "Epoch 5/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.7374e-04\n",
            "Epoch 6/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 8.1275e-04\n",
            "Epoch 7/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 8.6572e-04\n",
            "Epoch 8/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 7.7350e-05\n",
            "Epoch 9/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 5.0655e-04\n",
            "Epoch 10/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.0817e-05\n",
            "Epoch 11/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.6526e-04\n",
            "Epoch 12/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 2.9777e-04\n",
            "Epoch 13/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 8.3403e-05\n",
            "Epoch 14/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.4214e-04\n",
            "Epoch 15/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 6.9768e-04\n",
            "Epoch 16/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 9.9171e-05\n",
            "Epoch 17/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 0.0010\n",
            "Epoch 18/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.5705e-04\n",
            "Epoch 19/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 8.0359e-05\n",
            "Epoch 20/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.1460e-05\n",
            "Epoch 21/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 4.3675e-05\n",
            "Epoch 22/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.9668e-04\n",
            "Epoch 23/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.6526e-04\n",
            "Epoch 24/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.4214e-04\n",
            "Epoch 25/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 4.5513e-06\n",
            "Epoch 26/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.1564e-04\n",
            "Epoch 27/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.8457e-05\n",
            "Epoch 28/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.3392e-05\n",
            "Epoch 29/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 5.5634e-04\n",
            "Epoch 30/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 7.6862e-04\n",
            "Epoch 31/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 4.1746e-04\n",
            "Epoch 32/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 4.7790e-04\n",
            "Epoch 33/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 0.0010\n",
            "Epoch 34/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.3339e-05\n",
            "Epoch 35/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 0.0014\n",
            "Epoch 36/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.2073e-04\n",
            "Epoch 37/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.1564e-04\n",
            "Epoch 38/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.1926e-04\n",
            "Epoch 39/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.4519e-04\n",
            "Epoch 40/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 0.0010\n",
            "Epoch 41/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.8249e-04\n",
            "Epoch 42/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.7374e-04\n",
            "Epoch 43/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.8457e-05\n",
            "Epoch 44/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.0244e-04\n",
            "Epoch 45/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 8.1275e-04\n",
            "Epoch 46/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 4.7790e-04\n",
            "Epoch 47/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.6828e-04\n",
            "Epoch 48/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.9098e-04\n",
            "Epoch 49/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.3461e-04\n",
            "Epoch 50/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.8687e-04\n",
            "Epoch 51/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.7160e-04\n",
            "Epoch 52/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.5091e-04\n",
            "Epoch 53/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 5.0655e-04\n",
            "Epoch 54/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.0962e-05\n",
            "Epoch 55/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 0.0010\n",
            "Epoch 56/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 7.7350e-05\n",
            "Epoch 57/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 4.0687e-04\n",
            "Epoch 58/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 2.6544e-04\n",
            "Epoch 59/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 4.0687e-04\n",
            "Epoch 60/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.1926e-04\n",
            "Epoch 61/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 6.1770e-04\n",
            "Epoch 62/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 5.5634e-04\n",
            "Epoch 63/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 5.1701e-05\n",
            "Epoch 64/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.6168e-05\n",
            "Epoch 65/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.9619e-04\n",
            "Epoch 66/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.7374e-04\n",
            "Epoch 67/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 9.2751e-05\n",
            "Epoch 68/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 2.5844e-05\n",
            "Epoch 69/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.6828e-04\n",
            "Epoch 70/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 4.4001e-04\n",
            "Epoch 71/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.5946e-04\n",
            "Epoch 72/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 4.5513e-06\n",
            "Epoch 73/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 5.9563e-04\n",
            "Epoch 74/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 0.0012\n",
            "Epoch 75/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 6.8344e-06\n",
            "Epoch 76/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.6828e-04\n",
            "Epoch 77/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.4135e-04\n",
            "Epoch 78/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 2.8436e-04\n",
            "Epoch 79/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.8249e-04\n",
            "Epoch 80/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 8.9598e-05\n",
            "Epoch 81/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 8.0359e-05\n",
            "Epoch 82/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 6.4177e-04\n",
            "Epoch 83/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 6.5643e-05\n",
            "Epoch 84/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.8457e-05\n",
            "Epoch 85/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 6.5643e-05\n",
            "Epoch 86/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 2.3392e-05\n",
            "Epoch 87/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.9155e-04\n",
            "Epoch 88/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 2.9777e-04\n",
            "Epoch 89/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 7.1431e-05\n",
            "Epoch 90/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.6947e-04\n",
            "Epoch 91/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 1.1250e-04\n",
            "Epoch 92/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 4.6324e-05\n",
            "Epoch 93/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.5946e-04\n",
            "Epoch 94/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 1.7374e-04\n",
            "Epoch 95/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.7742e-04\n",
            "Epoch 96/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 3.5946e-04\n",
            "Epoch 97/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 0.0010\n",
            "Epoch 98/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 9.1372e-06\n",
            "Epoch 99/100\n",
            "117/117 [==============================] - 3s 24ms/step - loss: nan - accuracy: 3.5091e-04\n",
            "Epoch 100/100\n",
            "117/117 [==============================] - 3s 25ms/step - loss: nan - accuracy: 4.6324e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89a0295550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT0-gO47vlGR"
      },
      "source": [
        "def gen(model, seq, max_len = 20):\n",
        "    ''' Generates a sequence given a string seq using specified model until the total sequence length\n",
        "    reaches max_len'''\n",
        "    # Tokenize the input string\n",
        "    tokenized_sent = tokenizer.texts_to_sequences([seq])\n",
        "    max_len = max_len+len(tokenized_sent[0])\n",
        "    # If sentence is not as long as the desired sentence length, we need to 'pad sequence' so that\n",
        "    # the array input shape is correct going into our LSTM. the `pad_sequences` function adds \n",
        "    # zeroes to the left side of our sequence until it becomes 19 long, the number of input features.\n",
        "    while len(tokenized_sent[0]) < max_len:\n",
        "        padded_sentence = pad_sequences(tokenized_sent[-19:],maxlen=19)\n",
        "        op = model.predict(np.asarray(padded_sentence).reshape(1,-1))\n",
        "        tokenized_sent[0].append(op.argmax()+1)\n",
        "        \n",
        "    return \" \".join(map(lambda x : reverse_word_map[x],tokenized_sent[0]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIvxi26_b1Qe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00fba98e-2242-4eb9-f1e2-be365b4b66d2"
      },
      "source": [
        "gen(model, \"Hi\", max_len=20)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hi i i i i i i i i i i i i i i i i i i i i'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD_JH7S_b6jw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}